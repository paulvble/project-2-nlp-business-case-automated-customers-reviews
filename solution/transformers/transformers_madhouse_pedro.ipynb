{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2fb5ef-7a25-4da1-8ee6-6911687a2b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:01<00:00, 16.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoTokenizer, LEDForConditionalGeneration\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Load the dataset\n",
    "data_path = Path('..') / 'data' / 'data.csv'\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"The file at {data_path} does not exist.\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Select relevant columns\n",
    "data = data[[\"primaryCategories\", \"reviews.text\", \"reviews.rating\"]]\n",
    "\n",
    "# Drop rows with missing values in the specified columns (if any)\n",
    "data.dropna(subset=['primaryCategories', 'reviews.text', 'reviews.rating'], inplace=True)\n",
    "\n",
    "# Convert ratings to string to ensure consistent grouping\n",
    "data['reviews.rating'] = data['reviews.rating'].astype(str)\n",
    "\n",
    "# Group reviews by primary category and star rating and concatenate all reviews within each group\n",
    "grouped_reviews = data.groupby(['primaryCategories', 'reviews.rating'])['reviews.text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")\n",
    "model = LEDForConditionalGeneration.from_pretrained(\"allenai/led-base-16384\")\n",
    "\n",
    "# Check if GPU is available and use it\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to split text into chunks based on sentences\n",
    "def split_into_chunks(text, max_chunk_length):\n",
    "    sentences = text.split('. ')\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(tokenizer.encode(sentence))\n",
    "        if current_length + sentence_length <= max_chunk_length:\n",
    "            current_chunk.append(sentence)\n",
    "            current_length += sentence_length\n",
    "        else:\n",
    "            chunks.append('. '.join(current_chunk) + '.')\n",
    "            current_chunk = [sentence]\n",
    "            current_length = sentence_length\n",
    "    if current_chunk:\n",
    "        chunks.append('. '.join(current_chunk) + '.')\n",
    "    return chunks\n",
    "\n",
    "# Function to summarize text, handling long texts by chunking\n",
    "def summarize_text(text, max_chunk_length=4096, summary_max_length=50, summary_min_length=20):\n",
    "    chunks = split_into_chunks(text, max_chunk_length)\n",
    "    \n",
    "    # Summarize each chunk\n",
    "    chunk_summaries = []\n",
    "    for chunk in chunks:\n",
    "        inputs = tokenizer(chunk, return_tensors='pt', truncation=True, max_length=max_chunk_length)\n",
    "        inputs = inputs.to(device)\n",
    "        summary_ids = model.generate(inputs['input_ids'], max_length=summary_max_length, min_length=summary_min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        chunk_summaries.append(summary)\n",
    "    \n",
    "    # Combine the summaries and summarize them if necessary\n",
    "    combined_summary = ' '.join(chunk_summaries)\n",
    "    if len(tokenizer.encode(combined_summary)) > max_chunk_length:\n",
    "        final_summary = summarize_text(combined_summary, max_chunk_length, summary_max_length, summary_min_length)\n",
    "    else:\n",
    "        final_summary = combined_summary\n",
    "    \n",
    "    return final_summary\n",
    "\n",
    "# Apply summarization to each group of reviews using parallel processing\n",
    "def process_row(row):\n",
    "    return summarize_text(row['reviews.text'])\n",
    "\n",
    "grouped_reviews['summary'] = Parallel(n_jobs=-1, timeout=None)(delayed(process_row)(row) for idx, row in tqdm(grouped_reviews.iterrows(), total=grouped_reviews.shape[0]))\n",
    "\n",
    "# Display the summaries\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n",
    "\n",
    "# Visualize the reviews and their summaries\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Original Reviews: {row['reviews.text'][:1000]}...\")  # Print only the first 1000 characters of the original reviews\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b706e6-817c-462a-9796-1277c12a89cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'current_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save the summarized reviews to a CSV file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_dir\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummarized_reviews.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m grouped_reviews\u001b[38;5;241m.\u001b[39mto_csv(output_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarized reviews saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'current_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the summarized reviews to a CSV file\n",
    "output_path = current_dir / 'summarized_reviews.csv'\n",
    "grouped_reviews.to_csv(output_path, index=False)\n",
    "print(f\"Summarized reviews saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62eaa28-1d5a-4386-8cc9-0a508992df32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 3891 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3858 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3851 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3842 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3811 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3875 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3849 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3806 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3810 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3859 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3817 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3799 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3835 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3813 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3812 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3839 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3803 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3769 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3850 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3836 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3828 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3830 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3805 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3821 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3878 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3901 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3748 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3809 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3829 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3853 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3867 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3846 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3863 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3833 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3818 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3862 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3820 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3815 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3822 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3831 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3826 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3808 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3845 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3840 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3824 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3881 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3837 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3844 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3800 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3778 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3864 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3761 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3083 to 4096 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Category: Electronics, Star Rating: 5\n",
      "Summary: ) Buy, etc.) I noticed a cheap laptop sleeve (as in cheap quality) was nearly 16! I was like HECK NO! So I jumped on Amazon (btw amazon is the best shoutout to all the hard workers . Nice length on cord. Quality is outstanding! Would I recommend this product Absolutely! Worked on an android phone on a recent trip when a friend forgot their charger. Works great on my Kindle Fire as well! Just what I needed!  is better than the Echo! Portable - YES! Sound Quality - OFF THE CHARTS! I blue-tooth this to my computer and listen to movies with GREAT Dolby sound quality. Great sound in a small package for the money and It does a great job of being portable and easy to use. It does a great job of being portable and easy to use. It does a great job of being portable and easy to use. It does a great job of being portable and ...but you will lose bass if it's at max volume (not recommended if you like bass) We use this speaker all the time. It's perfect. I would buy this time and time again. Works great if you plan to have 't let the size fool you the sound is only short of Bose when it comes to volume and sound quality. Important note...You don't have to have an Echo to use this device. Yes, it's portable, can operate wireless , I didn't research a lot but I did read about it a little. Bought the Echo Tap, Echo Dot, Philips Hue Starter Kit and a Honeywell Thermostat for my wife for her birthday.She loves it and so do  product for reading ebooks. I have been using the paperwhite for about 2 years now and this unit definitely beats it. I also like the ability to get word definitions and the expansion or text ability. We got this for my wife to I love the fact it is back lit and I don't need a book light. Exceeded my expectation. I am a book addict and the savings over printed material allows me to buy more books. The availability of reference texts is increasing It is about as close as you can come to an actual book. I love my Kindle. You can read anywhere even outside in the sun. I read more than ever :) This kindle is a great product. I really enjoy it. Over all, though very happy with it I was in need of a new Kindle. We were going on several trips and I needed it immediately. The person at Best Buy that helped me was excellent! He helped thru the entire setting up process . Why spend hundreds on something for basic kids needs? I'm sure this will last him a few years and is well worth the price. This Amazon Fire is perfect for what I need - nice screen and memory size, really nice apps pre  will be able to keep in contact with them. Bought this as a Christmas gift for my wife. She is an avid reader. She previously had a B&N Nook which stopped working. This is much nicer and she loves it. d 8 reviewed throughly elsewhere many times for its solid performance for money. I mainly wanna talk about excellent buying experience at local best buy. It was not in Stock but employee we extra miles to locate the stock somewhe re but I like ,. The quality is awesome the pictures is good and clear... Excellent value, great product. It has a really solid feel. I am very happy with the purchase. I love my Fire HD8 I got it because my Kindle(the original It's good budget tablet for someone who wants to use light apps, video streaming, and internet.1.5gb ram is enough for most apps.16g memory and sd card slot gives enough space. It's good budget tablet for , has amazing battery life and has a pretty decent screen. Sure the Galaxy tablets have better specs, but it's the price and features you get from Amazon that make this device amazing! I needed something that's not an ipad for basic Great price for a great price for a great price for a great price for a great price for a great price for a great price for a great price for a great price for a great price for a great price for a great price for a , but think this might be a great less expensive option for me as well. Bought this for my son,, the size is perfect not too small not too big. Kid friendly..and easy to use. Overall o rate it 5 stars.. . I went in looking for a tablet for my daughter and she loved it. She loves it! She loves it! She loves it! She loves it! She loves it! She loves it! She loves it! She loves it! Will recommend it to others. I love to read and this tablet work great for my needs. I love to read and this tablet work great for my needs. I love to read and this tablet work great for my needs. I love to I have been a Kindle Fire user for years. This new one is amazing. I like being able to store information on a SD card. I love Amazon Fire HD8... It is so easy to use and perfect for reading books on or  can watch movies or stream music. I love the size of this tablet. I have an Ipad and think I prefer this size. It's easy to carry and a great size for reading. Got it for Christmas and am loving it! Easy to use and handy to have with you instead of a heavy laptop. Not an iPad, but that's not what I wanted. High quality, does everything I need it to do. Purchased for my granddaughter and it was a great  is enjoying it. this tablet is awesome. the fact that I can use a micro sd card to have more memory and can listen to my content on the card is great. the additional screen size is what I wanted and it has not disappointed Also, very easy set up and use! Was looking for a tablet to run my remote music server with from my easy chair. Was looking for a tablet to run my remote music server with from my easy chair. My first tablet I bought I only wish this was a Kindle Oasis. I would love to have a Kindle Oasis. I would love to have a Kindle Oasis. I would love to have a Kindle Oasis. I would love to have a Kindle O My kids love this tablet. They love it. They love it. They love it. They love it. They love it. They love it. They love it. They love it. They love it. They love it. They love 's rain, we didn't see any northern lights. Good thing I had my own personal entertainment system--Fire 7 tablet. Bought the Amazon Fire tablet and love it. Beyond my expectations. Great value for the money. So happy I made Does it quickly do all sorts of business spreadsheets applications, etc? No. Does it do everything that an i-pad etc can do? No. But at this price point it can't be beat. People say that you can't Easy to use with great picture. I would recommend it to a friend. Faster and good quality for this kind of tablet. I would recommend it to a friend. I would recommend it to a friend. I would recommend it to a friend Great product simple easy to understand great value!!!! I bought this as a Christmas present for my 11yr old granddaughter for Christmas. It's easy to use, lightweight and doesn't seem to have a lot of bugs or glitches. It's a It is taking me a while to learn the differences but most of them are improvements. The front and rear camera are easy to use and once we added FB, sharing photos was easy. Amazon apps are native to the device, so we have No other case compares to this one. It has held up well for me. I love it. I love it. I love it. I love it. I love it. I love it. I love it. I love it. Her and my other daughter we're sharing and Samsung tablet but because in such a fan of Amazon I decided to do research and I ended up getting here this one and she loves it. She even said it has more features than her previous one  love my Fire. Lightweight and very easy to use!! So glad I chose to buy this Kindie on BF. It is still a great price regardless for such a quality product. Made well, feels solid not cheap and chency Her parents are tech savy and they are impressed with it. Purchased 3 as gifts for grandchildren and they are a big hit already. We bought this for Christmas for our girl. I went to the store but they didn‚� It very light, great display and very easy to use. It does everything well. Easy to use and a great size. This is my first tablet and I made a very good choice. My daughter loves it! Easy to use and long 'd suggest Amazon - Fire HD 8 - 8\" - Tablet - 32GB 7th I had one of the original Kindle Fire tablets and it was good, but this one is so much more. Good work! Bought two for our 5- who was already an Amazon tablet users, this one was a tad bigger and has served her well. the price for performance is exceptional. highly recommended. The price for the price for the price for the price for the price for the price for rd tablet the screen seems bigger in this one and I love it! I use it for all of my media internet searches and needs kindle fire 8 has everything you could want in a tablet. My 1 1/2 yr old uses this  new one also has more storage! Great price for a great product. I‚Äôve never heard any complaints about the kindle brand nor do I have any. Very happy with my purchase. I love the Amazon Kindle Fire The tablet is great for kids. The tablet is great for kids. The amount of educational programs available for free in Freetime is absolutely staggering. My son suddenly knew things I hadn't taught him, and when I asked him where he ôs not a big deal for me. Amazing tablet for the money. Gave one to my wife for Christmas and she loves it Bought at best buy because I had a rewards certificate. Didn't have color I wanted but still works great I could set her as a user and make it safe for her age. I downloaded books and apps with ease. I'm glad that she is loving her Fire. Very easy to use bought it for my son. he likes it. very It is, very basic, but, I mostly use it for entertainment. It is the perfect size for sitting in a coffee shop or on your couch to read a book or watch your favorite tv show. I like to read and the kind Video was better than reviews stated, books load faster than my old one Still getting used to a new OS but I am very pleased This tablet is perfect for travel! Recently took it on a trip and the battery lasted the entire day with watching It's very easy to use... This was a great tablet for my wife. It is very easy to use. It is very easy to use. It is very easy to use. It is very easy to use. It is very easy Went with the higher storage 16gb over 8 even though you can buy micro sd cards up to 128gb now. Picked up a case at BB (1/2 price) and a micro sd (32gb).Just wait till I believe it is just a great tablet. I bought it for my grandson and he loves it. He loves it. He loves it. He loves it. He loves it. He uses it mostly for reading and some internet browsing. Overall Have a Child's Browsing & Adult Browsing With Parental Locks. Love this tablet have had several others but this brand works everytime..very happy with my purchase It has a clear screen, the books are easy to Love this product, and don't know why it took so l Lighter weight than my old kindle fire. Great price too. The amazon fire tablet is easy to use and set-up great tablet. Love this tablet. I I bought the kids protective case to use when the grandkids come over. Great quality, great price and best of all has good sound. Great tablet for kids very entertaining and informative for kids learning Great tablet with good parental controls for kids!! . As advertised. Very easy to set up profiles with daily goals and limits. Great purchase. My son loves it. Light weight. Good price for a great product. I would purchase another one. Pretty good tablet. Very durable and my Best buy ever!! This was the perfect gift for my 5 year old girl. She immediately fell in love with it. And the fact that it has a year damage warranty, it was a no brainer Easy for my kid to use , plus the cost, I just had to buy it. My child loves it. My child loves it. My child loves playing with the Kindle fire. It is entertaining and educational. My child loves this device. She doesn't stop playing But when we are out its a good tablet for a toddler who's learning. Has lots of games and activities for learning, parental controls, which I find extremely necessary for the internet today! My 3 1/2 year old grandson son L Other kids enjoy it while they are around with them. It keeps them entertained. Great tablet for kids. I like that I can have contol over what she can watch and play. I purchased this tablet for my 10 year old son and They like the idea they have an iPad like the adults. Well implemented. Great for my kiddo! He loves to watch Sesame Street on it :) I love the parental controls available. You can set what time they can start and It has lots of fun apps for kids. This tablet is perfect for kids. This tablet is perfect for kids under 12 years. It has lots of fun apps for the kids. I am new at tablets and look forward to enjoying learning all Purchased for my son who loves to read books. He loves to read books. He loves to read books. He loves to read books. He loves to read books. He loves to read books. He loves to read books. It is a great tablet. It is a great tablet. It is a great tablet. It is a great tablet. It is a great tablet. It is a great tablet. It is a great tablet. It is a great tablet. Great warranty also as a great value for the kids and the parents Bought this for my daughter for christmas. I know she will like playing games on it I would recommend this for kids ages 6 to 10. They can play games on it It even comes with the bumper cover. Great buy. Is great for beginners I love the parental control on it it works great for my toddler. Its a good tablet. I swapped out the case for one with a handle so she can carry Love this!!!!It is kidproof...I have a active 1 year old grandson who enjoy it very much!!! My 4 year old grandson enjoys 'playing' with his tablet.. I say playing because he thinks most of the programs on it are , lots of content. games books etc and easy for my 4 y.o to use. Great, non-expensive item for my kids to us and not destroy my Ipad. Bought this nice kindle fire kids tablet for my 18 He proudly proclaims to everyone he meets to check out his cool tablet. He especially loves the Freetime app. A Christmas gift for my granddaughter. It was a big hit! Great tablet. It came loaded with a lot of good They can their favorite kids show from youtube, Netflix etc. The cover is really good. I'm gonna another one for my daughter. I'm gonna another one for my son. I'm gonna another one for my grandson. I'm gonna If you use amazon prime this is a great tablet. If you use amazon prime this is a great tablet. I love it. I am extremely pleased. Fast. Efficient. Reliable. Purchased this for my wife during I bought this as a Christmas gift for my son. Very easy to use. I went to program it for her and she insisted on doing it herself. She was able to no problem! its very easy to set up and use. love 't get over how much I like this one. The 8 inch version is a good size and a lot easier to carry around than my heavier 10 inch tablet. I read negative reviews about the video quality but I have not had any issues and Most people will go with a bigger more sofisticated iPad or Samsung but this is a good product for a child to pass time or someone not wanting all the bells and whistles This is a very good product my kids do homework on This tablet is a deal!!! This is just an awesome tablet for the price and the features it has This is a great tablet for the price and the features it has This is a great device for my sons games since he was always using It has good connection to wi if. The kindle store is a breeze. The kindle store is a breeze. The picture quality is good. And seems to be the perfect size. A nice alternative compared to The more expensive tablet. very nice and very cheap..worth for what i paid.. I highly recommend this for beginners Great table I pay cheap price for this tablet I pay for this tablet I pay for this tablet I pay for this tablet I pay for this tablet I Does great on browsing and doing research easy to use and love the features especially the private browsing a great price as well Was looking for an inexpensive tablet for our child. Got this while on sale and ordered a screen protector and child case. Has Enjoy the multifaceted opportunities that are available with the Kindle BOUGHT MINE ON BLACK FRIDAY AND IT IS AWESOME. MY FIRST TABLET AND IT IS GREAT WITH ALL OF THE AMAZON FEATURES. . I traded it for Christmas and am loving it! I haven't tried to take any pictures yet and I didn't really purchase it for taking photos. I saw the reviews before purchasing and they were not good regarding photo quality. Again, Good thing, because I dropped the other one without the case on it and it cracked. Hands down a great update to my first gen Kindle. Worthwhile! Had the Fire HD 7\" before and just wanted to upgrade. Loving it so This is for my 10 year old. Love the tablet. Love the tablet. Love the tablet. Love the tablet. Love the tablet. Love the tablet. Love the tablet. Love the tablet. Love the tablet. Love the tablet. this has opened up my long forgotten youth with music and videos. This is the best tablet I have ever bought. This is the best tablet I have ever bought. I love the convenience of books when I travel, along with any apps I\n",
      "\n",
      "Primary Category: Electronics, Star Rating: 5\n",
      "Original Reviews: Great case to keep everything in its place! My husband love it!!!! Holds a lot of cds! After discarding and getting rid of broken cd cases, broken cds, and selecting those ones we really like, this binder turned up to be an excellent option to store our favourite cds and dvds and keep them in a small space at our living room, giving us the choice to donate or get rid of those cds towers that took a lot of room, despite looking nice. And because you can turn the pages, you can spot the cd you want to play without the hassle of taking it from a case that is falling apart. After storing them cds, all the cases and printed covers went straight to the recycling centre. We have a small version to put those cds my husband would like to listen to whenever he must drive away for work. A few dollars more, but I am boycotting amazon Pros: Standard Echo. Cons: Older generation Echo. Other Thoughts: Arrived on time and was new in box. Pros: Got it for under 50, much impressive sound than 2nd gen. H...\n",
      "Summary: ) Buy, etc.) I noticed a cheap laptop sleeve (as in cheap quality) was nearly 16! I was like HECK NO! So I jumped on Amazon (btw amazon is the best shoutout to all the hard workers . Nice length on cord. Quality is outstanding! Would I recommend this product Absolutely! Worked on an android phone on a recent trip when a friend forgot their charger. Works great on my Kindle Fire as well! Just what I needed!  is better than the Echo! Portable - YES! Sound Quality - OFF THE CHARTS! I blue-tooth this to my computer and listen to movies with GREAT Dolby sound quality. Great sound in a small package for the money and It does a great job of being portable and easy to use. It does a great job of being portable and easy to use. It does a great job of being portable and easy to use. It does a great job of being portable and ...but you will lose bass if it's at max volume (not recommended if you like bass) We use this speaker all the time. It's perfect. I would buy this time and time again. Works great if you plan to have 't let the size fool you the sound is only short of Bose when it comes to volume and sound quality. Important note...You don't have to have an Echo to use this device. Yes, it's portable, can operate wireless , I didn't research a lot but I did read about it a little. Bought the Echo Tap, Echo Dot, Philips Hue Starter Kit and a Honeywell Thermostat for my wife for her birthday.She loves it and so do  product for reading ebooks. I have been using the paperwhite for about 2 years now and this unit definitely beats it. I also like the ability to get word definitions and the expansion or text ability. We got this for my wife to I love the fact it is back lit and I don't need a book light. Exceeded my expectation. I am a book addict and the savings over printed material allows me to buy more books. The availability of reference texts is increasing It is about as close as you can come to an actual book. I love my Kindle. You can read anywhere even outside in the sun. I read more than ever :) This kindle is a great product. I really enjoy it. Over all, though very happy with it I was in need of a new Kindle. We were going on several trips and I needed it immediately. The person at Best Buy that helped me was excellent! He helped thru the entire setting up process . Why spend hundreds on something for basic kids needs? I'm sure this will last him a few years and is well worth the price. This Amazon Fire is perfect for what I need - nice screen and memory size, really nice apps pre  will be able to keep in contact with them. Bought this as a Christmas gift for my wife. She is an avid reader. She previously had a B&N Nook which stopped working. This is much nicer and she loves it. d 8 reviewed throughly elsewhere many times for its solid performance for money. I mainly wanna talk about excellent buying experience at local best buy. It was not in Stock but employee we extra miles to locate the stock somewhe re but I like ,. The quality is awesome the pictures is good and clear... Excellent value, great product. It has a really solid feel. I am very happy with the purchase. I love my Fire HD8 I got it because my Kindle(the original It's good budget tablet for someone who wants to use light apps, video streaming, and internet.1.5gb ram is enough for most apps.16g memory and sd card slot gives enough space. It's good budget tablet for , has amazing battery life and has a pretty decent screen. Sure the Galaxy tablets have better specs, but it's the price and features you get from Amazon that make this device amazing! I needed something that's not an ipad for basic Great price for a great price for a great price for a great price for a great price for a great price for a great price for a great price for a great price for a great price for a great price for a great price for a , but think this might be a great less expensive option for me as well. Bought this for my son,, the size is perfect not too small not too big. Kid friendly..and easy to use. Overall o rate it 5 stars.. . I went in looking for a tablet for my daughter and she loved it. She loves it! She loves it! She loves it! She loves it! She loves it! She loves it! She loves it! She loves it! Will recommend it to others. I love to read and this tablet work great for my needs. I love to read and this tablet work great for my needs. I love to read and this tablet work great for my needs. I love to I have been a Kindle Fire user for years. This new one is amazing. I like being able to store information on a SD card. I love Amazon Fire HD8... It is so easy to use and perfect for reading books on or  can watch movies or stream music. I love the size of this tablet. I have an Ipad and think I prefer this size. It's easy to carry and a great size for reading. Got it for Christmas and am loving it! Easy to use and handy to have with you instead of a heavy laptop. Not an iPad, but that's not what I wanted. High quality, does everything I need it to do. Purchased for my granddaughter and it was a great  is enjoying it. this tablet is awesome. the fact that I can use a micro sd card to have more memory and can listen to my content on the card is great. the additional screen size is what I wanted and it has not disappointed Also, very easy set up and use! Was looking for a tablet to run my remote music server with from my easy chair. Was looking for a tablet to run my remote music server with from my easy chair. My first tablet I bought I only wish this was a Kindle Oasis. I would love to have a Kindle Oasis. I would love to have a Kindle Oasis. I would love to have a Kindle Oasis. I would love to have a Kindle O My kids love this tablet. They love it. They love it. They love it. They love it. They love it. They love it. They love it. They love it. They love it. They love it. They love 's rain, we didn't see any northern lights. Good thing I had my own personal entertainment system--Fire 7 tablet. Bought the Amazon Fire tablet and love it. Beyond my expectations. Great value for the money. So happy I made Does it quickly do all sorts of business spreadsheets applications, etc? No. Does it do everything that an i-pad etc can do? No. But at this price point it can't be beat. People say that you can't Easy to use with great picture. I would recommend it to a friend. Faster and good quality for this kind of tablet. I would recommend it to a friend. I would recommend it to a friend. I would recommend it to a friend Great product simple easy to understand great value!!!! I bought this as a Christmas present for my 11yr old granddaughter for Christmas. It's easy to use, lightweight and doesn't seem to have a lot of bugs or glitches. It's a It is taking me a while to learn the differences but most of them are improvements. The front and rear camera are easy to use and once we added FB, sharing photos was easy. Amazon apps are native to the device, so we have No other case compares to this one. It has held up well for me. I love it. I love it. I love it. I love it. I love it. I love it. I love it. I love it. Her and my other daughter we're sharing and Samsung tablet but because in such a fan of Amazon I decided to do research and I ended up getting here this one and she loves it. She even said it has more features than her previous one  love my Fire. Lightweight and very easy to use!! So glad I chose to buy this Kindie on BF. It is still a great price regardless for such a quality product. Made well, feels solid not cheap and chency Her parents are tech savy and they are impressed with it. Purchased 3 as gifts for grandchildren and they are a big hit already. We bought this for Christmas for our girl. I went to the store but they didn‚� It very light, great display and very easy to use. It does everything well. Easy to use and a great size. This is my first tablet and I made a very good choice. My daughter loves it! Easy to use and long 'd suggest Amazon - Fire HD 8 - 8\" - Tablet - 32GB 7th I had one of the original Kindle Fire tablets and it was good, but this one is so much more. Good work! Bought two for our 5- who was already an Amazon tablet users, this one was a tad bigger and has served her well. the price for performance is exceptional. highly recommended. The price for the price for the price for the price for the price for the price for rd tablet the screen seems bigger in this one and I love it! I use it for all of my media internet searches and needs kindle fire 8 has everything you could want in a tablet. My 1 1/2 yr old uses this  new one also has more storage! Great price for a great product. I‚Äôve never heard any complaints about the kindle brand nor do I have any. Very happy with my purchase. I love the Amazon Kindle Fire The tablet is great for kids. The tablet is great for kids. The amount of educational programs available for free in Freetime is absolutely staggering. My son suddenly knew things I hadn't taught him, and when I asked him where he ôs not a big deal for me. Amazing tablet for the money. Gave one to my wife for Christmas and she loves it Bought at best buy because I had a rewards certificate. Didn't have color I wanted but still works great I could set her as a user and make it safe for her age. I downloaded books and apps with ease. I'm glad that she is loving her Fire. Very easy to use bought it for my son. he likes it. very It is, very basic, but, I mostly use it for entertainment. It is the perfect size for sitting in a coffee shop or on your couch to read a book or watch your favorite tv show. I like to read and the kind Video was better than reviews stated, books load faster than my old one Still getting used to a new OS but I am very pleased This tablet is perfect for travel! Recently took it on a trip and the battery lasted the entire day with watching It's very easy to use... This was a great tablet for my wife. It is very easy to use. It is very easy to use. It is very easy to use. It is very easy to use. It is very easy Went with the higher storage 16gb over 8 even though you can buy micro sd cards up to 128gb now. Picked up a case at BB (1/2 price) and a micro sd (32gb).Just wait till I believe it is just a great tablet. I bought it for my grandson and he loves it. He loves it. He loves it. He loves it. He loves it. He uses it mostly for reading and some internet browsing. Overall Have a Child's Browsing & Adult Browsing With Parental Locks. Love this tablet have had several others but this brand works everytime..very happy with my purchase It has a clear screen, the books are easy to Love this product, and don't know why it took so l Lighter weight than my old kindle fire. Great price too. The amazon fire tablet is easy to use and set-up great tablet. Love this tablet. I I bought the kids protective case to use when the grandkids come over. Great quality, great price and best of all has good sound. Great tablet for kids very entertaining and informative for kids learning Great tablet with good parental controls for kids!! . As advertised. Very easy to set up profiles with daily goals and limits. Great purchase. My son loves it. Light weight. Good price for a great product. I would purchase another one. Pretty good tablet. Very durable and my Best buy ever!! This was the perfect gift for my 5 year old girl. She immediately fell in love with it. And the fact that it has a year damage warranty, it was a no brainer Easy for my kid to use , plus the cost, I just had to buy it. My child loves it. My child loves it. My child loves playing with the Kindle fire. It is entertaining and educational. My child loves this device. She doesn't stop playing But when we are out its a good tablet for a toddler who's learning. Has lots of games and activities for learning, parental controls, which I find extremely necessary for the internet today! My 3 1/2 year old grandson son L Other kids enjoy it while they are around with them. It keeps them entertained. Great tablet for kids. I like that I can have contol over what she can watch and play. I purchased this tablet for my 10 year old son and They like the idea they have an iPad like the adults. Well implemented. Great for my kiddo! He loves to watch Sesame Street on it :) I love the parental controls available. You can set what time they can start and It has lots of fun apps for kids. This tablet is perfect for kids. This tablet is perfect for kids under 12 years. It has lots of fun apps for the kids. I am new at tablets and look forward to enjoying learning all Purchased for my son who loves to read books. He loves to read books. He loves to read books. He loves to read books. He loves to read books. He loves to read books. He loves to read books. It is a great tablet. It is a great tablet. It is a great tablet. It is a great tablet. It is a great tablet. It is a great tablet. It is a great tablet. It is a great tablet. Great warranty also as a great value for the kids and the parents Bought this for my daughter for christmas. I know she will like playing games on it I would recommend this for kids ages 6 to 10. They can play games on it It even comes with the bumper cover. Great buy. Is great for beginners I love the parental control on it it works great for my toddler. Its a good tablet. I swapped out the case for one with a handle so she can carry Love this!!!!It is kidproof...I have a active 1 year old grandson who enjoy it very much!!! My 4 year old grandson enjoys 'playing' with his tablet.. I say playing because he thinks most of the programs on it are , lots of content. games books etc and easy for my 4 y.o to use. Great, non-expensive item for my kids to us and not destroy my Ipad. Bought this nice kindle fire kids tablet for my 18 He proudly proclaims to everyone he meets to check out his cool tablet. He especially loves the Freetime app. A Christmas gift for my granddaughter. It was a big hit! Great tablet. It came loaded with a lot of good They can their favorite kids show from youtube, Netflix etc. The cover is really good. I'm gonna another one for my daughter. I'm gonna another one for my son. I'm gonna another one for my grandson. I'm gonna If you use amazon prime this is a great tablet. If you use amazon prime this is a great tablet. I love it. I am extremely pleased. Fast. Efficient. Reliable. Purchased this for my wife during I bought this as a Christmas gift for my son. Very easy to use. I went to program it for her and she insisted on doing it herself. She was able to no problem! its very easy to set up and use. love 't get over how much I like this one. The 8 inch version is a good size and a lot easier to carry around than my heavier 10 inch tablet. I read negative reviews about the video quality but I have not had any issues and Most people will go with a bigger more sofisticated iPad or Samsung but this is a good product for a child to pass time or someone not wanting all the bells and whistles This is a very good product my kids do homework on This tablet is a deal!!! This is just an awesome tablet for the price and the features it has This is a great tablet for the price and the features it has This is a great device for my sons games since he was always using It has good connection to wi if. The kindle store is a breeze. The kindle store is a breeze. The picture quality is good. And seems to be the perfect size. A nice alternative compared to The more expensive tablet. very nice and very cheap..worth for what i paid.. I highly recommend this for beginners Great table I pay cheap price for this tablet I pay for this tablet I pay for this tablet I pay for this tablet I pay for this tablet I Does great on browsing and doing research easy to use and love the features especially the private browsing a great price as well Was looking for an inexpensive tablet for our child. Got this while on sale and ordered a screen protector and child case. Has Enjoy the multifaceted opportunities that are available with the Kindle BOUGHT MINE ON BLACK FRIDAY AND IT IS AWESOME. MY FIRST TABLET AND IT IS GREAT WITH ALL OF THE AMAZON FEATURES. . I traded it for Christmas and am loving it! I haven't tried to take any pictures yet and I didn't really purchase it for taking photos. I saw the reviews before purchasing and they were not good regarding photo quality. Again, Good thing, because I dropped the other one without the case on it and it cracked. Hands down a great update to my first gen Kindle. Worthwhile! Had the Fire HD 7\" before and just wanted to upgrade. Loving it so This is for my 10 year old. Love the tablet. Love the tablet. Love the tablet. Love the tablet. Love the tablet. Love the tablet. Love the tablet. Love the tablet. Love the tablet. Love the tablet. this has opened up my long forgotten youth with music and videos. This is the best tablet I have ever bought. This is the best tablet I have ever bought. I love the convenience of books when I travel, along with any apps I\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoTokenizer, LEDForConditionalGeneration\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the dataset\n",
    "data_path = Path('..') / 'data' / 'data.csv'\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"The file at {data_path} does not exist.\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Select relevant columns\n",
    "data = data[[\"primaryCategories\", \"reviews.text\", \"reviews.rating\"]]\n",
    "\n",
    "# Drop rows with missing values in the specified columns (if any)\n",
    "data.dropna(subset=['primaryCategories', 'reviews.text', 'reviews.rating'], inplace=True)\n",
    "\n",
    "# Convert ratings to string to ensure consistent grouping\n",
    "data['reviews.rating'] = data['reviews.rating'].astype(str)\n",
    "\n",
    "# Filter the data for a specific category and 5-star rating\n",
    "category = \"Electronics\"  # Example category, change as needed\n",
    "rating = \"5\"\n",
    "filtered_data = data[(data['primaryCategories'] == category) & (data['reviews.rating'] == rating)]\n",
    "\n",
    "# Concatenate all reviews within the selected group\n",
    "grouped_reviews = filtered_data.groupby(['primaryCategories', 'reviews.rating'])['reviews.text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")\n",
    "model = LEDForConditionalGeneration.from_pretrained(\"allenai/led-base-16384\")\n",
    "\n",
    "# Check if GPU is available and use it\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to split text into chunks based on sentences\n",
    "def split_into_chunks(text, max_chunk_length):\n",
    "    sentences = text.split('. ')\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(tokenizer.encode(sentence))\n",
    "        if current_length + sentence_length <= max_chunk_length:\n",
    "            current_chunk.append(sentence)\n",
    "            current_length += sentence_length\n",
    "        else:\n",
    "            chunks.append('. '.join(current_chunk) + '.')\n",
    "            current_chunk = [sentence]\n",
    "            current_length = sentence_length\n",
    "    if current_chunk:\n",
    "        chunks.append('. '.join(current_chunk) + '.')\n",
    "    return chunks\n",
    "\n",
    "# Function to summarize text, handling long texts by chunking\n",
    "def summarize_text(text, max_chunk_length=4096, summary_max_length=50, summary_min_length=20):\n",
    "    chunks = split_into_chunks(text, max_chunk_length)\n",
    "    \n",
    "    # Summarize each chunk\n",
    "    chunk_summaries = []\n",
    "    for chunk in chunks:\n",
    "        inputs = tokenizer(chunk, return_tensors='pt', truncation=True, max_length=max_chunk_length)\n",
    "        inputs = inputs.to(device)\n",
    "        summary_ids = model.generate(inputs['input_ids'], max_length=summary_max_length, min_length=summary_min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        chunk_summaries.append(summary)\n",
    "    \n",
    "    # Combine the summaries and summarize them if necessary\n",
    "    combined_summary = ' '.join(chunk_summaries)\n",
    "    if len(tokenizer.encode(combined_summary)) > max_chunk_length:\n",
    "        final_summary = summarize_text(combined_summary, max_chunk_length, summary_max_length, summary_min_length)\n",
    "    else:\n",
    "        final_summary = combined_summary\n",
    "    \n",
    "    return final_summary\n",
    "\n",
    "# Apply summarization to the selected group of reviews\n",
    "grouped_reviews['summary'] = grouped_reviews['reviews.text'].apply(lambda x: summarize_text(x))\n",
    "\n",
    "# Display the summary for the selected combination\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n",
    "\n",
    "# Visualize the reviews and their summaries\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Original Reviews: {row['reviews.text'][:1000]}...\")  # Print only the first 1000 characters of the original reviews\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1253005b-0837-4ceb-aea5-aef4ae60391c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Primary Category: Electronics, Star Rating: 5\n",
      "Summary: ) Buy, etc.) I noticed a cheap laptop sleeve (as in cheap quality) was nearly 16! I was like HECK NO! So I jumped on Amazon (btw amazon is the best shoutout to all the hard workers\n",
      "\n",
      "Primary Category: Electronics, Star Rating: 5\n",
      "Original Reviews: Great case to keep everything in its place! My husband love it!!!! Holds a lot of cds! After discarding and getting rid of broken cd cases, broken cds, and selecting those ones we really like, this binder turned up to be an excellent option to store our favourite cds and dvds and keep them in a small space at our living room, giving us the choice to donate or get rid of those cds towers that took a lot of room, despite looking nice. And because you can turn the pages, you can spot the cd you want to play without the hassle of taking it from a case that is falling apart. After storing them cds, all the cases and printed covers went straight to the recycling centre. We have a small version to put those cds my husband would like to listen to whenever he must drive away for work. A few dollars more, but I am boycotting amazon Pros: Standard Echo. Cons: Older generation Echo. Other Thoughts: Arrived on time and was new in box. Pros: Got it for under 50, much impressive sound than 2nd gen. H...\n",
      "Summary: ) Buy, etc.) I noticed a cheap laptop sleeve (as in cheap quality) was nearly 16! I was like HECK NO! So I jumped on Amazon (btw amazon is the best shoutout to all the hard workers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoTokenizer, LEDForConditionalGeneration\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the dataset\n",
    "data_path = Path('..') / 'data' / 'data.csv'\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"The file at {data_path} does not exist.\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Select relevant columns\n",
    "data = data[[\"primaryCategories\", \"reviews.text\", \"reviews.rating\"]]\n",
    "\n",
    "# Drop rows with missing values in the specified columns (if any)\n",
    "data.dropna(subset=['primaryCategories', 'reviews.text', 'reviews.rating'], inplace=True)\n",
    "\n",
    "# Convert ratings to string to ensure consistent grouping\n",
    "data['reviews.rating'] = data['reviews.rating'].astype(str)\n",
    "\n",
    "# Filter the data for a specific category and 5-star rating\n",
    "category = \"Electronics\"  # Example category, change as needed\n",
    "rating = \"5\"\n",
    "filtered_data = data[(data['primaryCategories'] == category) & (data['reviews.rating'] == rating)]\n",
    "\n",
    "# Concatenate all reviews within the selected group\n",
    "grouped_reviews = filtered_data.groupby(['primaryCategories', 'reviews.rating'])['reviews.text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")\n",
    "model = LEDForConditionalGeneration.from_pretrained(\"allenai/led-base-16384\")\n",
    "\n",
    "# Check if GPU is available and use it\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to split text into chunks based on sentences\n",
    "def split_into_chunks(text, max_chunk_length):\n",
    "    sentences = text.split('. ')\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(tokenizer.encode(sentence))\n",
    "        if current_length + sentence_length <= max_chunk_length:\n",
    "            current_chunk.append(sentence)\n",
    "            current_length += sentence_length\n",
    "        else:\n",
    "            chunks.append('. '.join(current_chunk) + '.')\n",
    "            current_chunk = [sentence]\n",
    "            current_length = sentence_length\n",
    "    if current_chunk:\n",
    "        chunks.append('. '.join(current_chunk) + '.')\n",
    "    return chunks\n",
    "\n",
    "# Function to summarize text, handling long texts by chunking\n",
    "def summarize_text(text, max_chunk_length=4096, summary_max_length=50, summary_min_length=10):\n",
    "    chunks = split_into_chunks(text, max_chunk_length)\n",
    "    \n",
    "    # Summarize each chunk\n",
    "    chunk_summaries = []\n",
    "    for chunk in chunks:\n",
    "        inputs = tokenizer(chunk, return_tensors='pt', truncation=True, max_length=max_chunk_length)\n",
    "        inputs = inputs.to(device)\n",
    "        summary_ids = model.generate(inputs['input_ids'], max_length=summary_max_length, min_length=summary_min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        chunk_summaries.append(summary)\n",
    "    \n",
    "    # Combine the summaries and summarize them if necessary\n",
    "    combined_summary = ' '.join(chunk_summaries)\n",
    "    while len(tokenizer.encode(combined_summary)) > summary_max_length:\n",
    "        inputs = tokenizer(combined_summary, return_tensors='pt', truncation=True, max_length=max_chunk_length)\n",
    "        inputs = inputs.to(device)\n",
    "        summary_ids = model.generate(inputs['input_ids'], max_length=summary_max_length, min_length=summary_min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "        combined_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return combined_summary\n",
    "\n",
    "# Apply summarization to the selected group of reviews\n",
    "grouped_reviews['summary'] = grouped_reviews['reviews.text'].apply(lambda x: summarize_text(x))\n",
    "\n",
    "# Display the summary for the selected combination\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n",
    "\n",
    "# Visualize the reviews and their summaries\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Original Reviews: {row['reviews.text'][:1000]}...\")  # Print only the first 1000 characters of the original reviews\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0789314b-55f1-4c15-87de-73eefb15419a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 102\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_summary\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Apply summarization to the selected group of reviews\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m grouped_reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgrouped_reviews\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreviews.text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msummarize_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Display the summary for the selected combination\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m grouped_reviews\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\series.py:4917\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[12], line 102\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_summary\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Apply summarization to the selected group of reviews\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m grouped_reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m grouped_reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviews.text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43msummarize_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Display the summary for the selected combination\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m grouped_reviews\u001b[38;5;241m.\u001b[39miterrows():\n",
      "Cell \u001b[1;32mIn[12], line 78\u001b[0m, in \u001b[0;36msummarize_text\u001b[1;34m(text, max_chunk_length, summary_max_length, summary_min_length)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Ensure correct tensor shapes and types\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     summary_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msummary_max_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msummary_min_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     summary \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(summary_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     87\u001b[0m     chunk_summaries\u001b[38;5;241m.\u001b[39mappend(summary)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\transformers\\generation\\utils.py:1948\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1940\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1941\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1942\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   1943\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1944\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1945\u001b[0m     )\n\u001b[0;32m   1947\u001b[0m     \u001b[38;5;66;03m# 14. run beam sample\u001b[39;00m\n\u001b[1;32m-> 1948\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_beam_search(\n\u001b[0;32m   1949\u001b[0m         input_ids,\n\u001b[0;32m   1950\u001b[0m         beam_scorer,\n\u001b[0;32m   1951\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   1952\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mprepared_logits_warper,\n\u001b[0;32m   1953\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   1954\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   1955\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1956\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1957\u001b[0m     )\n\u001b[0;32m   1959\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[0;32m   1960\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   1961\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   1962\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1963\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1969\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   1970\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\transformers\\generation\\utils.py:2909\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   2906\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m stack_model_outputs(outputs_per_sub_batch)\n\u001b[0;32m   2908\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Unchanged original behavior\u001b[39;00m\n\u001b[1;32m-> 2909\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\n\u001b[0;32m   2910\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[0;32m   2911\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2912\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   2913\u001b[0m         output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   2914\u001b[0m     )\n\u001b[0;32m   2916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2917\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1747\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1743\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[0;32m   1744\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1745\u001b[0m         )\n\u001b[1;32m-> 1747\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1759\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1760\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1765\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1766\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m lm_logits \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\u001b[38;5;241m.\u001b[39mto(lm_logits\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1633\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1626\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[0;32m   1627\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   1628\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1629\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1630\u001b[0m     )\n\u001b[0;32m   1632\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1633\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1486\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1473\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1474\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1475\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1483\u001b[0m         use_cache,\n\u001b[0;32m   1484\u001b[0m     )\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m   1494\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1499\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:791\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[0;32m    790\u001b[0m cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m    800\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:603\u001b[0m, in \u001b[0;36mBartSdpaAttention.forward\u001b[1;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    599\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_causal \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;66;03m# NOTE: SDPA with memory-efficient backend is currently (torch==2.1.2) bugged when using non-contiguous inputs and a custom attn_mask,\u001b[39;00m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;66;03m# but we are fine here as `_shape` do call `.contiguous()`. Reference: https://github.com/pytorch/pytorch/issues/112577\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m (bsz, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim):\n\u001b[0;32m    613\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    614\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`attn_output` should be of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(bsz,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\u001b[38;5;250m \u001b[39mtgt_len,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    615\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_output\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    616\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load the dataset\n",
    "data_path = Path('..') / 'data' / 'data.csv'\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"The file at {data_path} does not exist.\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Select relevant columns\n",
    "data = data[[\"primaryCategories\", \"reviews.text\", \"reviews.rating\"]]\n",
    "\n",
    "# Drop rows with missing values in the specified columns (if any)\n",
    "data.dropna(subset=['primaryCategories', 'reviews.text', 'reviews.rating'], inplace=True)\n",
    "\n",
    "# Convert ratings to string to ensure consistent grouping\n",
    "data['reviews.rating'] = data['reviews.rating'].astype(str)\n",
    "\n",
    "# Filter the data for a specific category and 5-star rating\n",
    "category = \"Electronics\"  # Example category, change as needed\n",
    "rating = \"5\"\n",
    "filtered_data = data[(data['primaryCategories'] == category) & (data['reviews.rating'] == rating)]\n",
    "\n",
    "# Concatenate all reviews within the selected group\n",
    "grouped_reviews = filtered_data.groupby(['primaryCategories', 'reviews.rating'])['reviews.text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Check if GPU is available and use it\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Debugging: Enable CUDA launch blocking\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# Temporarily use CPU to check if it's a GPU issue\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to split text into chunks based on maximum length\n",
    "def split_into_chunks(text, max_length):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for word in words:\n",
    "        word_length = len(tokenizer.encode(word, add_special_tokens=False))\n",
    "        if current_length + word_length <= max_length:\n",
    "            current_chunk.append(word)\n",
    "            current_length += word_length\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_length = word_length\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "# Function to summarize text by chunking\n",
    "def summarize_text(text, max_chunk_length=1024, summary_max_length=150, summary_min_length=30):\n",
    "    chunks = split_into_chunks(text, max_chunk_length)\n",
    "    \n",
    "    # Summarize each chunk\n",
    "    chunk_summaries = []\n",
    "    for chunk in chunks:\n",
    "        inputs = tokenizer(chunk, return_tensors='pt', truncation=True, max_length=max_chunk_length)\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # Ensure correct tensor shapes and types\n",
    "        try:\n",
    "            summary_ids = model.generate(\n",
    "                inputs['input_ids'], \n",
    "                max_length=summary_max_length, \n",
    "                min_length=summary_min_length, \n",
    "                length_penalty=2.0, \n",
    "                num_beams=4, \n",
    "                early_stopping=True\n",
    "            )\n",
    "            summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "            chunk_summaries.append(summary)\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error processing chunk: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Combine the summaries and summarize them if necessary\n",
    "    combined_summary = ' '.join(chunk_summaries)\n",
    "    if len(tokenizer.encode(combined_summary)) > max_chunk_length:\n",
    "        final_summary = summarize_text(combined_summary, max_chunk_length, summary_max_length, summary_min_length)\n",
    "    else:\n",
    "        final_summary = combined_summary\n",
    "    \n",
    "    return final_summary\n",
    "\n",
    "# Apply summarization to the selected group of reviews\n",
    "grouped_reviews['summary'] = grouped_reviews['reviews.text'].apply(lambda x: summarize_text(x))\n",
    "\n",
    "# Display the summary for the selected combination\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n",
    "\n",
    "# Visualize the reviews and their summaries\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Original Reviews: {row['reviews.text'][:1000]}...\")  # Print only the first 1000 characters of the original reviews\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7145dff3-7790-4cc5-bacc-91717ba8a706",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Category: Electronics, Star Rating: 5\n",
      "Summary: She loves it and it is easy for her to use I love my new Fire HD! I had one of the first generation Kindle Fire, and loved it, love this one even more!!! This 8\" tablet is much better than the older 7\" tablet. Bought this for an older person and it's a simple tablet to use at their age she loves it Bought this tablet for my daughter for christmas, great quality for the price! Clear picture, easy to use and easy to set up, great for surfing the web or watching movies on Fire is great. Great tablet for the grandkids, they love it great item Great tablet for the kids and adults great features like the rubber case and free features for kids I bought this tablet for my daughter and she loves it I buy this tablet for my nephew and he is happy with it. No problems with tablet, kids love it and the size is great My wife and kids love easy to use and the size is perfect I was going to get a Samsung tablet but for doing everything this is better I got it for my kid and she loves it. No problems with tablet, kids love it and the size is great My wife and kids love easy to use and the size is perfect I was going to get a Samsung tablet but for doing everything this is better I got it for my kid and she loves it.\n",
      "\n",
      "Primary Category: Electronics, Star Rating: 5\n",
      "Original Reviews: Great case to keep everything in its place! My husband love it!!!! Holds a lot of cds! After discarding and getting rid of broken cd cases, broken cds, and selecting those ones we really like, this binder turned up to be an excellent option to store our favourite cds and dvds and keep them in a small space at our living room, giving us the choice to donate or get rid of those cds towers that took a lot of room, despite looking nice. And because you can turn the pages, you can spot the cd you want to play without the hassle of taking it from a case that is falling apart. After storing them cds, all the cases and printed covers went straight to the recycling centre. We have a small version to put those cds my husband would like to listen to whenever he must drive away for work. A few dollars more, but I am boycotting amazon Pros: Standard Echo. Cons: Older generation Echo. Other Thoughts: Arrived on time and was new in box. Pros: Got it for under 50, much impressive sound than 2nd gen. H...\n",
      "Summary: She loves it and it is easy for her to use I love my new Fire HD! I had one of the first generation Kindle Fire, and loved it, love this one even more!!! This 8\" tablet is much better than the older 7\" tablet. Bought this for an older person and it's a simple tablet to use at their age she loves it Bought this tablet for my daughter for christmas, great quality for the price! Clear picture, easy to use and easy to set up, great for surfing the web or watching movies on Fire is great. Great tablet for the grandkids, they love it great item Great tablet for the kids and adults great features like the rubber case and free features for kids I bought this tablet for my daughter and she loves it I buy this tablet for my nephew and he is happy with it. No problems with tablet, kids love it and the size is great My wife and kids love easy to use and the size is perfect I was going to get a Samsung tablet but for doing everything this is better I got it for my kid and she loves it. No problems with tablet, kids love it and the size is great My wife and kids love easy to use and the size is perfect I was going to get a Samsung tablet but for doing everything this is better I got it for my kid and she loves it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoTokenizer, LEDForConditionalGeneration\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the dataset\n",
    "data_path = Path('..') / 'data' / 'data.csv'\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"The file at {data_path} does not exist.\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Select relevant columns\n",
    "data = data[[\"primaryCategories\", \"reviews.text\", \"reviews.rating\"]]\n",
    "\n",
    "# Drop rows with missing values in the specified columns (if any)\n",
    "data.dropna(subset=['primaryCategories', 'reviews.text', 'reviews.rating'], inplace=True)\n",
    "\n",
    "# Convert ratings to string to ensure consistent grouping\n",
    "data['reviews.rating'] = data['reviews.rating'].astype(str)\n",
    "\n",
    "# Filter the data for a specific category and 5-star rating\n",
    "category = \"Electronics\"  # Example category, change as needed\n",
    "rating = \"5\"\n",
    "filtered_data = data[(data['primaryCategories'] == category) & (data['reviews.rating'] == rating)]\n",
    "\n",
    "# Concatenate all reviews within the selected group\n",
    "grouped_reviews = filtered_data.groupby(['primaryCategories', 'reviews.rating'])['reviews.text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Function to clean and tokenize text\n",
    "def clean_and_tokenize(text):\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Function to extract key sentences\n",
    "def extract_key_sentences(text, num_sentences=5):\n",
    "    # Split text into sentences\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "    \n",
    "    # Clean and tokenize sentences\n",
    "    cleaned_sentences = [clean_and_tokenize(sentence) for sentence in sentences]\n",
    "    \n",
    "    # Create TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer().fit_transform(cleaned_sentences)\n",
    "    vectors = vectorizer.toarray()\n",
    "    \n",
    "    # Calculate sentence importance\n",
    "    sentence_scores = linear_kernel(vectors, vectors).sum(axis=1)\n",
    "    \n",
    "    # Extract top sentences\n",
    "    top_sentence_indices = sentence_scores.argsort()[-num_sentences:]\n",
    "    top_sentences = [sentences[i] for i in top_sentence_indices]\n",
    "    \n",
    "    return ' '.join(top_sentences)\n",
    "\n",
    "# Apply extraction and summarization to the selected group of reviews\n",
    "grouped_reviews['summary'] = grouped_reviews['reviews.text'].apply(lambda x: extract_key_sentences(x))\n",
    "\n",
    "# Display the summary for the selected combination\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n",
    "\n",
    "# Visualize the reviews and their summaries\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Original Reviews: {row['reviews.text'][:1000]}...\")  # Print only the first 1000 characters of the original reviews\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c50d7b7-9285-4856-9c4e-5ebc6e7d033c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pedro\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:603: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Category: Electronics, Star Rating: 5\n",
      "Summary: Amazon Tap Bluetooth and wifi wireless speaker works as advertised. Easy set up, tons of music, easy to use. Great range for asking questions.. Very enjoyable and easy for listening to music selections online. The Kindle Voyage 6 is better than the real thing. This is my third Kindle, I still have the other two; however, this has a camera and much larger screen. Bigger screen, longer battery life and faster loading. Amazon prime you get free movies, books, and games.\n",
      "\n",
      "Primary Category: Electronics, Star Rating: 5\n",
      "Original Reviews: Great case to keep everything in its place! My husband love it!!!! Holds a lot of cds! After discarding and getting rid of broken cd cases, broken cds, and selecting those ones we really like, this binder turned up to be an excellent option to store our favourite cds and dvds and keep them in a small space at our living room, giving us the choice to donate or get rid of those cds towers that took a lot of room, despite looking nice. And because you can turn the pages, you can spot the cd you want to play without the hassle of taking it from a case that is falling apart. After storing them cds, all the cases and printed covers went straight to the recycling centre. We have a small version to put those cds my husband would like to listen to whenever he must drive away for work. A few dollars more, but I am boycotting amazon Pros: Standard Echo. Cons: Older generation Echo. Other Thoughts: Arrived on time and was new in box. Pros: Got it for under 50, much impressive sound than 2nd gen. H...\n",
      "Summary: Amazon Tap Bluetooth and wifi wireless speaker works as advertised. Easy set up, tons of music, easy to use. Great range for asking questions.. Very enjoyable and easy for listening to music selections online. The Kindle Voyage 6 is better than the real thing. This is my third Kindle, I still have the other two; however, this has a camera and much larger screen. Bigger screen, longer battery life and faster loading. Amazon prime you get free movies, books, and games.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load the dataset\n",
    "data_path = Path('..') / 'data' / 'data.csv'\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"The file at {data_path} does not exist.\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Select relevant columns\n",
    "data = data[[\"primaryCategories\", \"reviews.text\", \"reviews.rating\"]]\n",
    "\n",
    "# Drop rows with missing values in the specified columns (if any)\n",
    "data.dropna(subset=['primaryCategories', 'reviews.text', 'reviews.rating'], inplace=True)\n",
    "\n",
    "# Convert ratings to string to ensure consistent grouping\n",
    "data['reviews.rating'] = data['reviews.rating'].astype(str)\n",
    "\n",
    "# Filter the data for a specific category and 5-star rating\n",
    "category = \"Electronics\"  # Example category, change as needed\n",
    "rating = \"5\"\n",
    "filtered_data = data[(data['primaryCategories'] == category) & (data['reviews.rating'] == rating)]\n",
    "\n",
    "# Concatenate all reviews within the selected group\n",
    "grouped_reviews = filtered_data.groupby(['primaryCategories', 'reviews.rating'])['reviews.text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Check if GPU is available and use it\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Debugging: Enable CUDA launch blocking\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# Clear the GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Optionally, delete the model and re-load it\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Re-load the model and tokenizer\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to split text into chunks based on maximum length\n",
    "def split_into_chunks(text, max_length):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for word in words:\n",
    "        word_length = len(tokenizer.encode(word, add_special_tokens=False))\n",
    "        if current_length + word_length <= max_length:\n",
    "            current_chunk.append(word)\n",
    "            current_length += word_length\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_length = word_length\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "# Function to summarize text by chunking\n",
    "def summarize_text(text, max_chunk_length=1024, summary_max_length=150, summary_min_length=30):\n",
    "    chunks = split_into_chunks(text, max_chunk_length)\n",
    "    \n",
    "    # Summarize each chunk\n",
    "    chunk_summaries = []\n",
    "    for chunk in chunks:\n",
    "        inputs = tokenizer(chunk, return_tensors='pt', truncation=True, max_length=max_chunk_length)\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # Ensure correct tensor shapes and types\n",
    "        try:\n",
    "            summary_ids = model.generate(\n",
    "                inputs['input_ids'], \n",
    "                max_length=summary_max_length, \n",
    "                min_length=summary_min_length, \n",
    "                length_penalty=2.0, \n",
    "                num_beams=4, \n",
    "                early_stopping=True\n",
    "            )\n",
    "            summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "            chunk_summaries.append(summary)\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error processing chunk: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Combine the summaries and summarize them if necessary\n",
    "    combined_summary = ' '.join(chunk_summaries)\n",
    "    if len(tokenizer.encode(combined_summary)) > max_chunk_length:\n",
    "        final_summary = summarize_text(combined_summary, max_chunk_length, summary_max_length, summary_min_length)\n",
    "    else:\n",
    "        final_summary = combined_summary\n",
    "    \n",
    "    return final_summary\n",
    "\n",
    "# Apply summarization to the selected group of reviews\n",
    "grouped_reviews['summary'] = grouped_reviews['reviews.text'].apply(lambda x: summarize_text(x))\n",
    "\n",
    "# Display the summary for the selected combination\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n",
    "\n",
    "# Visualize the reviews and their summaries\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Original Reviews: {row['reviews.text'][:1000]}...\")  # Print only the first 1000 characters of the original reviews\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47406d07-8e63-4b51-b07d-8716c6f17feb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Primary Category: Electronics, Star Rating: 5\n",
      "Summary: Amazon Tap Bluetooth and wifi wireless speaker works as advertised. Easy set up, tons of music, easy to use. Great range for asking questions.. Very enjoyable and easy for listening to music selections online. The Kindle Voyage 6 is better than the real thing. This is my third Kindle, I still have the other two; however, this has a camera and much larger screen. Bigger screen, longer battery life and faster loading. Amazon prime you get free movies, books, and games.\n",
      "\n",
      "Primary Category: Electronics, Star Rating: 5\n",
      "Original Reviews: Great case to keep everything in its place! My husband love it!!!! Holds a lot of cds! After discarding and getting rid of broken cd cases, broken cds, and selecting those ones we really like, this binder turned up to be an excellent option to store our favourite cds and dvds and keep them in a small space at our living room, giving us the choice to donate or get rid of those cds towers that took a lot of room, despite looking nice. And because you can turn the pages, you can spot the cd you want to play without the hassle of taking it from a case that is falling apart. After storing them cds, all the cases and printed covers went straight to the recycling centre. We have a small version to put those cds my husband would like to listen to whenever he must drive away for work. A few dollars more, but I am boycotting amazon Pros: Standard Echo. Cons: Older generation Echo. Other Thoughts: Arrived on time and was new in box. Pros: Got it for under 50, much impressive sound than 2nd gen. H...\n",
      "Summary: Amazon Tap Bluetooth and wifi wireless speaker works as advertised. Easy set up, tons of music, easy to use. Great range for asking questions.. Very enjoyable and easy for listening to music selections online. The Kindle Voyage 6 is better than the real thing. This is my third Kindle, I still have the other two; however, this has a camera and much larger screen. Bigger screen, longer battery life and faster loading. Amazon prime you get free movies, books, and games.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load the dataset\n",
    "data_path = Path('..') / 'data' / 'data.csv'\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"The file at {data_path} does not exist.\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Select relevant columns\n",
    "data = data[[\"primaryCategories\", \"reviews.text\", \"reviews.rating\"]]\n",
    "\n",
    "# Drop rows with missing values in the specified columns (if any)\n",
    "data.dropna(subset=['primaryCategories', 'reviews.text', 'reviews.rating'], inplace=True)\n",
    "\n",
    "# Convert ratings to string to ensure consistent grouping\n",
    "data['reviews.rating'] = data['reviews.rating'].astype(str)\n",
    "\n",
    "# Filter the data for a specific category and 5-star rating\n",
    "category = \"Electronics\"  # Example category, change as needed\n",
    "rating = \"5\"\n",
    "filtered_data = data[(data['primaryCategories'] == category) & (data['reviews.rating'] == rating)]\n",
    "\n",
    "# Concatenate all reviews within the selected group\n",
    "grouped_reviews = filtered_data.groupby(['primaryCategories', 'reviews.rating'])['reviews.text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Check if GPU is available and use it\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Debugging: Enable CUDA launch blocking\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# Clear the GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Optionally, delete the model and re-load it\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Re-load the model and tokenizer\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to split text into chunks based on maximum length\n",
    "def split_into_chunks(text, max_length):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for word in words:\n",
    "        word_length = len(tokenizer.encode(word, add_special_tokens=False))\n",
    "        if current_length + word_length <= max_length:\n",
    "            current_chunk.append(word)\n",
    "            current_length += word_length\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_length = word_length\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "# Function to summarize text by chunking with batch processing\n",
    "def summarize_text(text, max_chunk_length=1024, summary_max_length=150, summary_min_length=30, batch_size=8):\n",
    "    chunks = split_into_chunks(text, max_chunk_length)\n",
    "    \n",
    "    chunk_summaries = []\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors='pt', truncation=True, padding=True, max_length=max_chunk_length)\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # Generate summaries for the batch\n",
    "        summary_ids = model.generate(\n",
    "            inputs['input_ids'], \n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            max_length=summary_max_length, \n",
    "            min_length=summary_min_length, \n",
    "            length_penalty=2.0, \n",
    "            num_beams=4, \n",
    "            early_stopping=True\n",
    "        )\n",
    "        \n",
    "        # Decode the summaries\n",
    "        summaries = [tokenizer.decode(g, skip_special_tokens=True) for g in summary_ids]\n",
    "        chunk_summaries.extend(summaries)\n",
    "    \n",
    "    # Combine the summaries and summarize them if necessary\n",
    "    combined_summary = ' '.join(chunk_summaries)\n",
    "    if len(tokenizer.encode(combined_summary)) > max_chunk_length:\n",
    "        final_summary = summarize_text(combined_summary, max_chunk_length, summary_max_length, summary_min_length, batch_size)\n",
    "    else:\n",
    "        final_summary = combined_summary\n",
    "    \n",
    "    return final_summary\n",
    "\n",
    "# Apply summarization to the selected group of reviews\n",
    "grouped_reviews['summary'] = grouped_reviews['reviews.text'].apply(lambda x: summarize_text(x))\n",
    "\n",
    "# Display the summary for the selected combination\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n",
    "\n",
    "# Visualize the reviews and their summaries\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Original Reviews: {row['reviews.text'][:1000]}...\")  # Print only the first 1000 characters of the original reviews\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b365e17-4c4c-43e9-9a64-211f466f64c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4abc1199f144e89ae7917d4ab93baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0d7ee9928f40a486821c81e5e01844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47088e340783474e843f29f7964dabd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38bb967c2c74518aa424a99a7ff0def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead8036e9a6e46318c536d9d8064c527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe8b606aef14dcd98084577498085f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba39e1b25bfe4dfd9fcde510eda2606b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pedro\\anaconda3\\envs\\PytorchCudaEnv\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:603: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9666 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Category: Electronics, Star Rating: 5\n",
      "Summary: Great Product, Great Service, Great Price, Great Product, and Great Service! AmazonBasic Vent and Adjustable Laptop Stand is the Best! Best E-reader on the market, but a little pricey for what you get! Amazon Fire HD 8 is the best tablet I've ever owned! Best bang for your buck at a great price! Amazon Fire HD8 is a must have for anyone who loves Amazon and Amazon Prime! Amazon Fire is the best tablet in the market! Amazon Fire HD8 is the Best tablet for the price and great product for the money! Best bang for your buck tablet I've ever bought! Amazon Fire HD HD 8 Kids Edition is the best! Amazon's Kindle Fire FIre is the Best! Great tablet for kids and adults! Great product for the price and great quality for the money! Great features and fun for all ages and ages Best tablet for the price and great quality! Great for kids and adults at a great price! I love this tablet! I would definitely recommend to a friend. Great starter tablet for kids and easy to use and easy for kids to play games and watch cartoons! Highly recommend to all parents that have kids! Great product for kids and parents! Great product for the price and great product for a great price! Best tablet for the money and great quality! Best bang for your buck Android tablet for the buck at a great price! Amazon Fire HD8 is the best tablet I've ever owned! Great tablet for the price and great features! Highly recommend! Amazon Fire HD8 is the best tablet I've ever owned. Great for kids and adults awesome...\n",
      "\n",
      "Primary Category: Electronics, Star Rating: 5\n",
      "Original Reviews: Great case to keep everything in its place! My husband love it!!!! Holds a lot of cds! After discarding and getting rid of broken cd cases, broken cds, and selecting those ones we really like, this binder turned up to be an excellent option to store our favourite cds and dvds and keep them in a small space at our living room, giving us the choice to donate or get rid of those cds towers that took a lot of room, despite looking nice. And because you can turn the pages, you can spot the cd you want to play without the hassle of taking it from a case that is falling apart. After storing them cds, all the cases and printed covers went straight to the recycling centre. We have a small version to put those cds my husband would like to listen to whenever he must drive away for work. A few dollars more, but I am boycotting amazon Pros: Standard Echo. Cons: Older generation Echo. Other Thoughts: Arrived on time and was new in box. Pros: Got it for under 50, much impressive sound than 2nd gen. H...\n",
      "Summary: Great Product, Great Service, Great Price, Great Product, and Great Service! AmazonBasic Vent and Adjustable Laptop Stand is the Best! Best E-reader on the market, but a little pricey for what you get! Amazon Fire HD 8 is the best tablet I've ever owned! Best bang for your buck at a great price! Amazon Fire HD8 is a must have for anyone who loves Amazon and Amazon Prime! Amazon Fire is the best tablet in the market! Amazon Fire HD8 is the Best tablet for the price and great product for the money! Best bang for your buck tablet I've ever bought! Amazon Fire HD HD 8 Kids Edition is the best! Amazon's Kindle Fire FIre is the Best! Great tablet for kids and adults! Great product for the price and great quality for the money! Great features and fun for all ages and ages Best tablet for the price and great quality! Great for kids and adults at a great price! I love this tablet! I would definitely recommend to a friend. Great starter tablet for kids and easy to use and easy for kids to play games and watch cartoons! Highly recommend to all parents that have kids! Great product for kids and parents! Great product for the price and great product for a great price! Best tablet for the money and great quality! Best bang for your buck Android tablet for the buck at a great price! Amazon Fire HD8 is the best tablet I've ever owned! Great tablet for the price and great features! Highly recommend! Amazon Fire HD8 is the best tablet I've ever owned. Great for kids and adults awesome...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the dataset\n",
    "data_path = Path('..') / 'data' / 'data.csv'\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"The file at {data_path} does not exist.\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Select relevant columns\n",
    "data = data[[\"primaryCategories\", \"reviews.text\", \"reviews.rating\"]]\n",
    "\n",
    "# Drop rows with missing values in the specified columns (if any)\n",
    "data.dropna(subset=['primaryCategories', 'reviews.text', 'reviews.rating'], inplace=True)\n",
    "\n",
    "# Convert ratings to string to ensure consistent grouping\n",
    "data['reviews.rating'] = data['reviews.rating'].astype(str)\n",
    "\n",
    "# Filter the data for a specific category and 5-star rating\n",
    "category = \"Electronics\"  # Example category, change as needed\n",
    "rating = \"5\"\n",
    "filtered_data = data[(data['primaryCategories'] == category) & (data['reviews.rating'] == rating)]\n",
    "\n",
    "# Concatenate all reviews within the selected group\n",
    "grouped_reviews = filtered_data.groupby(['primaryCategories', 'reviews.rating'])['reviews.text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mabrouk/amazon-review-summarizer-bart\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mabrouk/amazon-review-summarizer-bart\")\n",
    "\n",
    "# Check if GPU is available and use it\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Debugging: Enable CUDA launch blocking\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# Clear the GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to split text into chunks based on maximum length\n",
    "def split_into_chunks(text, max_length):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for word in words:\n",
    "        word_length = len(tokenizer.encode(word, add_special_tokens=False))\n",
    "        if current_length + word_length <= max_length:\n",
    "            current_chunk.append(word)\n",
    "            current_length += word_length\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_length = word_length\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "# Function to summarize text by chunking with batch processing\n",
    "def summarize_text(text, max_chunk_length=1024, summary_max_length=150, summary_min_length=30, batch_size=8):\n",
    "    chunks = split_into_chunks(text, max_chunk_length)\n",
    "    \n",
    "    chunk_summaries = []\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors='pt', truncation=True, padding=True, max_length=max_chunk_length)\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # Generate summaries for the batch\n",
    "        summary_ids = model.generate(\n",
    "            inputs['input_ids'], \n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            max_length=summary_max_length, \n",
    "            min_length=summary_min_length, \n",
    "            length_penalty=2.0, \n",
    "            num_beams=4, \n",
    "            early_stopping=True\n",
    "        )\n",
    "        \n",
    "        # Decode the summaries\n",
    "        summaries = [tokenizer.decode(g, skip_special_tokens=True) for g in summary_ids]\n",
    "        chunk_summaries.extend(summaries)\n",
    "    \n",
    "    # Combine the summaries and summarize them if necessary\n",
    "    combined_summary = ' '.join(chunk_summaries)\n",
    "    if len(tokenizer.encode(combined_summary)) > max_chunk_length:\n",
    "        final_summary = summarize_text(combined_summary, max_chunk_length, summary_max_length, summary_min_length, batch_size)\n",
    "    else:\n",
    "        final_summary = combined_summary\n",
    "    \n",
    "    return final_summary\n",
    "\n",
    "# Apply summarization to the selected group of reviews\n",
    "grouped_reviews['summary'] = grouped_reviews['reviews.text'].apply(lambda x: summarize_text(x))\n",
    "\n",
    "# Display the summary for the selected combination\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n",
    "\n",
    "# Visualize the reviews and their summaries\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Original Reviews: {row['reviews.text'][:1000]}...\")  # Print only the first 1000 characters of the original reviews\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9871d95-924a-4507-b8cc-81a2065c5896",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9483 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Category: Electronics, Star Rating: 5\n",
      "Summary: Great Product, Great Service, Great Price, Great Product, and Great Service! AmazonBasic Vent and Adjustable Laptop Stand is the Best! Best E-reader on the market! Amazon Fire HD 8 is the best tablet I've ever owned! Highly recommend this product! Best tablet for the price and features I have ever used! Great tablet for all ages, great price, great features, great battery life! Amazon Fire HD8 is the best tablet for the price! Great for travel, travel, reading, and a great tablet for a great price! Best bang for your buck tablet I've ever bought! Amazon Fire HD 8.50 is a great tablet at a great price for a great product Best tablet for the price and great kid features! Great for travel, travel, school, music, games, movies, etc. Amazon Fire 7 inch tablet is a great product and works great and no issues This Amazon Fire is better then I expected. I love my new Fire tablet Best... Great starter tablet for kids and kids love it! Great price, great selection of apps, great protection, easy to set up and easy to use! Best tablet for kids and kids who like to play with it! Highly recommended to anyone who is in the market for a new tablet! Best bang for your buck tablet for the buck at a great price! Amazon Fire HD8 is the best tablet I've ever owned! Highly recommend this tablet for the new kindle! Best Tablet for the price point at a great price. Great tablet for general use and easy...\n",
      "\n",
      "Primary Category: Electronics, Star Rating: 5\n",
      "Original Reviews: Great case to keep everything in its place! My husband love it!!!! Holds a lot of cds! After discarding and getting rid of broken cd cases, broken cds, and selecting those ones we really like, this binder turned up to be an excellent option to store our favourite cds and dvds and keep them in a small space at our living room, giving us the choice to donate or get rid of those cds towers that took a lot of room, despite looking nice. And because you can turn the pages, you can spot the cd you want to play without the hassle of taking it from a case that is falling apart. After storing them cds, all the cases and printed covers went straight to the recycling centre. We have a small version to put those cds my husband would like to listen to whenever he must drive away for work. A few dollars more, but I am boycotting amazon Pros: Standard Echo. Cons: Older generation Echo. Other Thoughts: Arrived on time and was new in box. Pros: Got it for under 50, much impressive sound than 2nd gen. H...\n",
      "Summary: Great Product, Great Service, Great Price, Great Product, and Great Service! AmazonBasic Vent and Adjustable Laptop Stand is the Best! Best E-reader on the market! Amazon Fire HD 8 is the best tablet I've ever owned! Highly recommend this product! Best tablet for the price and features I have ever used! Great tablet for all ages, great price, great features, great battery life! Amazon Fire HD8 is the best tablet for the price! Great for travel, travel, reading, and a great tablet for a great price! Best bang for your buck tablet I've ever bought! Amazon Fire HD 8.50 is a great tablet at a great price for a great product Best tablet for the price and great kid features! Great for travel, travel, school, music, games, movies, etc. Amazon Fire 7 inch tablet is a great product and works great and no issues This Amazon Fire is better then I expected. I love my new Fire tablet Best... Great starter tablet for kids and kids love it! Great price, great selection of apps, great protection, easy to set up and easy to use! Best tablet for kids and kids who like to play with it! Highly recommended to anyone who is in the market for a new tablet! Best bang for your buck tablet for the buck at a great price! Amazon Fire HD8 is the best tablet I've ever owned! Highly recommend this tablet for the new kindle! Best Tablet for the price point at a great price. Great tablet for general use and easy...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the dataset\n",
    "data_path = Path('..') / 'data' / 'data.csv'\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"The file at {data_path} does not exist.\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Select relevant columns\n",
    "data = data[[\"primaryCategories\", \"reviews.text\", \"reviews.rating\"]]\n",
    "\n",
    "# Drop rows with missing values in the specified columns (if any)\n",
    "data.dropna(subset=['primaryCategories', 'reviews.text', 'reviews.rating'], inplace=True)\n",
    "\n",
    "# Convert ratings to string to ensure consistent grouping\n",
    "data['reviews.rating'] = data['reviews.rating'].astype(str)\n",
    "\n",
    "# Filter the data for a specific category and 5-star rating\n",
    "category = \"Electronics\"  # Example category, change as needed\n",
    "rating = \"5\"\n",
    "filtered_data = data[(data['primaryCategories'] == category) & (data['reviews.rating'] == rating)]\n",
    "\n",
    "# Concatenate all reviews within the selected group\n",
    "grouped_reviews = filtered_data.groupby(['primaryCategories', 'reviews.rating'])['reviews.text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mabrouk/amazon-review-summarizer-bart\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mabrouk/amazon-review-summarizer-bart\")\n",
    "\n",
    "# Check if GPU is available and use it\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Debugging: Enable CUDA launch blocking\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# Clear the GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to split text into chunks based on maximum length\n",
    "def split_into_chunks(text, max_length):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for word in words:\n",
    "        word_length = len(tokenizer.encode(word, add_special_tokens=False))\n",
    "        if current_length + word_length <= max_length:\n",
    "            current_chunk.append(word)\n",
    "            current_length += word_length\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_length = word_length\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "# Function to summarize text by chunking with batch processing\n",
    "def summarize_text(text, max_chunk_length=1024, summary_max_length=150, summary_min_length=30, batch_size=8):\n",
    "    chunks = split_into_chunks(text, max_chunk_length)\n",
    "    \n",
    "    chunk_summaries = []\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors='pt', truncation=True, padding=True, max_length=max_chunk_length)\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # Generate summaries for the batch\n",
    "        summary_ids = model.generate(\n",
    "            inputs['input_ids'], \n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            max_length=summary_max_length, \n",
    "            min_length=summary_min_length, \n",
    "            length_penalty=1.0,  # Adjust length penalty\n",
    "            num_beams=6,  # Increase number of beams\n",
    "            no_repeat_ngram_size=3,  # Prevent repetition of phrases\n",
    "            early_stopping=True\n",
    "        )\n",
    "        \n",
    "        # Decode the summaries\n",
    "        summaries = [tokenizer.decode(g, skip_special_tokens=True) for g in summary_ids]\n",
    "        chunk_summaries.extend(summaries)\n",
    "    \n",
    "    # Combine the summaries and summarize them if necessary\n",
    "    combined_summary = ' '.join(chunk_summaries)\n",
    "    if len(tokenizer.encode(combined_summary)) > max_chunk_length:\n",
    "        final_summary = summarize_text(combined_summary, max_chunk_length, summary_max_length, summary_min_length, batch_size)\n",
    "    else:\n",
    "        final_summary = combined_summary\n",
    "    \n",
    "    return final_summary\n",
    "\n",
    "# Apply summarization to the selected group of reviews\n",
    "grouped_reviews['summary'] = grouped_reviews['reviews.text'].apply(lambda x: summarize_text(x))\n",
    "\n",
    "# Display the summary for the selected combination\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n",
    "\n",
    "# Visualize the reviews and their summaries\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Original Reviews: {row['reviews.text'][:1000]}...\")  # Print only the first 1000 characters of the original reviews\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff3f91ed-d978-4f8a-9e50-2f88833fe099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9483 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Category: Electronics, Star Rating: 5\n",
      "Summary: Great Product, Great Service, Great Price, Great Product, and Great Service! AmazonBasic Vent and Adjustable Laptop Stand is the Best! Best E-reader on the market! Amazon Fire HD 8 is the best tablet I've ever owned! Highly recommend this product! Best tablet for the price and features I have ever used! Great tablet for all ages, great price, great features, great battery life! Amazon Fire HD8 is the best tablet for the price! Great for travel, travel, reading, and a great tablet for a great price! Best bang for your buck tablet I've ever bought! Amazon Fire HD 8.50 is a great tablet at a great price for a great product Best tablet for the price and great kid features! Great for travel, travel, school, music, games, movies, etc. Amazon Fire 7 inch tablet is a great product and works great and no issues This Amazon Fire is better then I expected. I love my new Fire tablet Best... Great starter tablet for kids and kids love it! Great price, great selection of apps, great protection, easy to set up and easy to use! Best tablet for kids and kids who like to play with it! Highly recommended to anyone who is in the market for a new tablet! Best bang for your buck tablet for the buck at a great price! Amazon Fire HD8 is the best tablet I've ever owned! Highly recommend this tablet for the new kindle! Best Tablet for the price point at a great price. Great tablet for general use and easy...\n",
      "\n",
      "Primary Category: Electronics, Star Rating: 5\n",
      "Original Reviews: Great case to keep everything in its place! My husband love it!!!! Holds a lot of cds! After discarding and getting rid of broken cd cases, broken cds, and selecting those ones we really like, this binder turned up to be an excellent option to store our favourite cds and dvds and keep them in a small space at our living room, giving us the choice to donate or get rid of those cds towers that took a lot of room, despite looking nice. And because you can turn the pages, you can spot the cd you want to play without the hassle of taking it from a case that is falling apart. After storing them cds, all the cases and printed covers went straight to the recycling centre. We have a small version to put those cds my husband would like to listen to whenever he must drive away for work. A few dollars more, but I am boycotting amazon Pros: Standard Echo. Cons: Older generation Echo. Other Thoughts: Arrived on time and was new in box. Pros: Got it for under 50, much impressive sound than 2nd gen. H...\n",
      "Summary: Great Product, Great Service, Great Price, Great Product, and Great Service! AmazonBasic Vent and Adjustable Laptop Stand is the Best! Best E-reader on the market! Amazon Fire HD 8 is the best tablet I've ever owned! Highly recommend this product! Best tablet for the price and features I have ever used! Great tablet for all ages, great price, great features, great battery life! Amazon Fire HD8 is the best tablet for the price! Great for travel, travel, reading, and a great tablet for a great price! Best bang for your buck tablet I've ever bought! Amazon Fire HD 8.50 is a great tablet at a great price for a great product Best tablet for the price and great kid features! Great for travel, travel, school, music, games, movies, etc. Amazon Fire 7 inch tablet is a great product and works great and no issues This Amazon Fire is better then I expected. I love my new Fire tablet Best... Great starter tablet for kids and kids love it! Great price, great selection of apps, great protection, easy to set up and easy to use! Best tablet for kids and kids who like to play with it! Highly recommended to anyone who is in the market for a new tablet! Best bang for your buck tablet for the buck at a great price! Amazon Fire HD8 is the best tablet I've ever owned! Highly recommend this tablet for the new kindle! Best Tablet for the price point at a great price. Great tablet for general use and easy...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the dataset\n",
    "data_path = Path('..') / 'data' / 'data.csv'\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"The file at {data_path} does not exist.\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Select relevant columns\n",
    "data = data[[\"primaryCategories\", \"reviews.text\", \"reviews.rating\"]]\n",
    "\n",
    "# Drop rows with missing values in the specified columns (if any)\n",
    "data.dropna(subset=['primaryCategories', 'reviews.text', 'reviews.rating'], inplace=True)\n",
    "\n",
    "# Convert ratings to string to ensure consistent grouping\n",
    "data['reviews.rating'] = data['reviews.rating'].astype(str)\n",
    "\n",
    "# Filter the data for a specific category and 5-star rating\n",
    "category = \"Electronics\"  # Example category, change as needed\n",
    "rating = \"5\"\n",
    "filtered_data = data[(data['primaryCategories'] == category) & (data['reviews.rating'] == rating)]\n",
    "\n",
    "# Concatenate all reviews within the selected group\n",
    "grouped_reviews = filtered_data.groupby(['primaryCategories', 'reviews.rating'])['reviews.text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mabrouk/amazon-review-summarizer-bart\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mabrouk/amazon-review-summarizer-bart\")\n",
    "\n",
    "# Check if GPU is available and use it\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Debugging: Enable CUDA launch blocking\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# Clear the GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to split text into chunks based on maximum length\n",
    "def split_into_chunks(text, max_length):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for word in words:\n",
    "        word_length = len(tokenizer.encode(word, add_special_tokens=False))\n",
    "        if current_length + word_length <= max_length:\n",
    "            current_chunk.append(word)\n",
    "            current_length += word_length\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_length = word_length\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "# Function to summarize text by chunking with batch processing\n",
    "def summarize_text(text, max_chunk_length=1024, summary_max_length=150, summary_min_length=30, batch_size=8):\n",
    "    chunks = split_into_chunks(text, max_chunk_length)\n",
    "    \n",
    "    chunk_summaries = []\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors='pt', truncation=True, padding=True, max_length=max_chunk_length)\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # Generate summaries for the batch\n",
    "        summary_ids = model.generate(\n",
    "            inputs['input_ids'], \n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            max_length=summary_max_length, \n",
    "            min_length=summary_min_length, \n",
    "            length_penalty=1.0,  # Adjust length penalty\n",
    "            num_beams=6,  # Increase number of beams\n",
    "            no_repeat_ngram_size=3,  # Prevent repetition of phrases\n",
    "            early_stopping=True\n",
    "        )\n",
    "        \n",
    "        # Decode the summaries\n",
    "        summaries = [tokenizer.decode(g, skip_special_tokens=True) for g in summary_ids]\n",
    "        chunk_summaries.extend(summaries)\n",
    "    \n",
    "    # Combine the summaries and summarize them if necessary\n",
    "    combined_summary = ' '.join(chunk_summaries)\n",
    "    if len(tokenizer.encode(combined_summary)) > max_chunk_length:\n",
    "        final_summary = summarize_text(combined_summary, max_chunk_length, summary_max_length, summary_min_length, batch_size)\n",
    "    else:\n",
    "        final_summary = combined_summary\n",
    "    \n",
    "    return final_summary\n",
    "\n",
    "# Function to remove repetitive phrases\n",
    "def remove_repetitive_phrases(text):\n",
    "    sentences = text.split('. ')\n",
    "    unique_sentences = []\n",
    "    seen_sentences = set()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if sentence not in seen_sentences:\n",
    "            unique_sentences.append(sentence)\n",
    "            seen_sentences.add(sentence)\n",
    "    \n",
    "    return '. '.join(unique_sentences)\n",
    "\n",
    "# Apply summarization to the selected group of reviews\n",
    "grouped_reviews['summary'] = grouped_reviews['reviews.text'].apply(lambda x: remove_repetitive_phrases(summarize_text(x)))\n",
    "\n",
    "# Display the summary for the selected combination\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n",
    "\n",
    "# Visualize the reviews and their summaries\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Original Reviews: {row['reviews.text'][:1000]}...\")  # Print only the first 1000 characters of the original reviews\n",
    "    print(f\"Summary: {row['summary']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba55267c-6e6e-4412-b25f-d25c591f5edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Category: Electronics, Star Rating: 5\n",
      "Original Length: 1390885 characters\n",
      "Summary Length: 1405 characters\n",
      "Summary: Great Product, Great Service, Great Price, Great Product, and Great Service! AmazonBasic Vent and Adjustable Laptop Stand is the Best! Best E-reader on the market! Amazon Fire HD 8 is the best tablet I've ever owned! Highly recommend this product! Best tablet for the price and features I have ever used! Great tablet for all ages, great price, great features, great battery life! Amazon Fire HD8 is the best tablet for the price! Great for travel, travel, reading, and a great tablet for a great price! Best bang for your buck tablet I've ever bought! Amazon Fire HD 8.50 is a great tablet at a great price for a great product Best tablet for the price and great kid features! Great for travel, travel, school, music, games, movies, etc. Amazon Fire 7 inch tablet is a great product and works great and no issues This Amazon Fire is better then I expected. I love my new Fire tablet Best... Great starter tablet for kids and kids love it! Great price, great selection of apps, great protection, easy to set up and easy to use! Best tablet for kids and kids who like to play with it! Highly recommended to anyone who is in the market for a new tablet! Best bang for your buck tablet for the buck at a great price! Amazon Fire HD8 is the best tablet I've ever owned! Highly recommend this tablet for the new kindle! Best Tablet for the price point at a great price. Great tablet for general use and easy...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the summary and check the lengths\n",
    "for idx, row in grouped_reviews.iterrows():\n",
    "    original_length = len(row['reviews.text'])\n",
    "    summary_length = len(row['summary'])\n",
    "    print(f\"Primary Category: {row['primaryCategories']}, Star Rating: {row['reviews.rating']}\")\n",
    "    print(f\"Original Length: {original_length} characters\")\n",
    "    print(f\"Summary Length: {summary_length} characters\")\n",
    "    print(f\"Summary: {row['summary']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c92d1f-3f5d-4953-8127-e9e058a0963d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
